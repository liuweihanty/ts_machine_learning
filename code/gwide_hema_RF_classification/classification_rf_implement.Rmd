---
title: "gwide_random_forest_implementation"
author: "Weihan Liu"
date: "17/02/2020"
output: html_document
---

##Install relevant packages
```{r,results='hide'}
library(randomForest)  #ML
library(caret)  #ML
library(ggplot2) #plotting
library(dplyr) #data manipulation
library(tibble) #data manipulation
library(stats) #data manipulation
```


##Read in files
```{r}

gwide_knn <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/gwide_dup_rm_knn.csv",stringsAsFactors = FALSE) 
str(gwide_knn)
```

some data cleaning
```{r}
set.seed(1278353)
#label the gene names to be rowname of the df
rownames(gwide_knn) <- make.names(gwide_knn$Gene,unique = TRUE)
gwide_knn <- select(gwide_knn, -c("X","Gene"))
head(gwide_knn)
```


Use the label from Cancer Gene Census as the ground truth instead of the TSGene
##Read in the data and switch the ground truth column
```{r}
#read in the CGC data
CGC_TS <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/GCG_TS.csv",stringsAsFactors = FALSE)
CGC_TS <- CGC_TS$Gene.Symbol 
CGC_TS <- as.data.frame(CGC_TS)
CGC_TS <- CGC_TS %>% mutate("TS_status" = 1) %>% rename(Gene = CGC_TS)

gwide_knn <- rownames_to_column(gwide_knn, var = "Gene")
#switch the ground truth column from TSGene to CGC
gwide_knn_CGC <- gwide_knn  %>%
        full_join(CGC_TS, by = "Gene")
#replace all the NAs in the TS_status columns with 0s
gwide_knn_CGC$TS_status[is.na(gwide_knn_CGC$TS_status)] <- 0

glimpse(gwide_knn_CGC)

```


##Split the training vs testing data
create training data, which is all of the non-chromosome 7 genes. The training data is unbalanced, majority of genes are non CGC labeled TS, so their TS status = 0
```{r}
gwide_train_CGC <- gwide_knn_CGC %>%
        filter(chromosome != 7 & chromosome != "MT")

table(gwide_train_CGC$chromosome)
```

Balance the training data set by sampling non-TS from the training data set using bootstrapping
```{r}
set.seed(683723)

#function to generate the balanced training data
# input is the unbalanced unsampled training data
train_data_generate <- function(train_data = gwide_train_CGC){

        gwide_train_balance_CGC <- filter(train_data,TS_status == 0) %>% 
                                grouped_df("chromosome") %>%
                                sample_frac(size = 0.02)
                        
        gwide_train_balance_CGC <- as.data.frame(gwide_train_balance_CGC)
        gwide_train_balance_CGC <- rbind(gwide_train_balance_CGC,filter(gwide_train_CGC,TS_status == 1))
        gwide_train_balance_CGC$TS_status <- as.factor(gwide_train_balance_CGC$TS_status)
        gwide_train_balance_CGC <- column_to_rownames(gwide_train_balance_CGC,var = "Gene")
        
        return(gwide_train_balance_CGC )
}


#run the function 100 times and store the resulted training data in a list
balanced_train_list  <- lapply(seq_len(100),function(x) train_data_generate(gwide_train_CGC))

```

Generate testing data
```{r}
#creating testing set, which will be all genes on chromosome 7
gwide_test_CGC <- gwide_knn_CGC %>%
        filter(chromosome == 7)
gwide_test_CGC$TS_status <- as.factor(gwide_test_CGC$TS_status)
gwide_test_CGC <- select(gwide_test_CGC, -"chromosome")
gwide_test_CGC <- column_to_rownames(gwide_test_CGC,var = "Gene")

str(gwide_test_CGC)

```


training data list: balanced_train_list
testing data: gwide_test_CGC

##Hyperparameter tuning
We will use a grid search based method to exhaustively search for the best combination hyperparameters, which will give the smallest OOB error
```{r}
#' @ntree: number of trees, default is 500
#' @mtry: number of variables randomly sampled as candidates at each split
#' @samplesize: number of samples(rows) to train on, default = 63.2%
#' @nodesize: minimum size(# of samples) pf the terminal nodes, if small, allows deeper and more complex tree
#' @maxnodes: maximum number of terminal nodes

#grid search
#Establish a list of possible values for mtry, nodesize and sampsize
mtry <- seq(4, ncol(balanced_train_list[[1]]) * 0.8, 2)
nodesize <- seq(3, 10, 2)
sampsize <- nrow(balanced_train_list[[1]]) * c(0.7,0.8)
#create an empty holder dataframe to hold all the hyperparatmeters creates for each boostrap

best_hyper_all <- data.frame()

hyper_parameter_tune <- function(train_data,mtry,nodesize,sampsize){
        for (k in 1:length(train_data)){
                # Create a data frame containing all combinations 
                hyper_grid <- expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
                # Create an empty vector to store OOB error values
                oob_err <- c()
                
                # Write a loop over the rows of hyper_grid to train the grid of models
                for (i in 1:nrow(hyper_grid)) {
                
                    # Train a Random Forest model
                    rf_model <- randomForest(formula = TS_status ~ ., 
                                          data = select(train_data[[k]],-c("chromosome")),
                                          mtry = hyper_grid$mtry[i],
                                          nodesize = hyper_grid$nodesize[i],
                                          sampsize = hyper_grid$sampsize[i])
                                          
                    # Store OOB error for the model                      
                    oob_err[i] <- rf_model$err.rate[nrow(rf_model$err.rate), "OOB"]
                }
        
                # Identify optimal set of hyperparmeters based on OOB error
                opt_i <- which.min(oob_err)
                best_hyper <- hyper_grid[opt_i,]
                best_hyper_all <- rbind(best_hyper_all,best_hyper) 
        }
       return(best_hyper_all)        
}  
```

```{r}
set.seed(57895758)
best_hyper_all <- hyper_parameter_tune(balanced_train_list,mtry,nodesize,sampsize) 
 
```


## fit of random forest model using the optimal hyperparameters
```{r, fig.height=4, fig.width=8}
set.seed(2245646)
#' @train_data_list: list of randomly sampled training data
#' @hyperparameter_grid: a dataframe of hyperparameteers corresponding to your training data list. Each training data in the list has a corresponding combination of hyperparameters


run_class_rf <- function(train_data_list = balanced_train_list,hyperparameter_grid = best_hyper_all) {
        rf_list <- vector(mode = "list",length = length(balanced_train_list)) #empty holder list to hold all the rf model 
        for (i in 1:length(train_data_list)) {
                rf = randomForest(TS_status ~ .,
                                  data = select(train_data_list[[i]],
                                   -"chromosome"),
                                  importance = TRUE,
                                  mtry = hyperparameter_grid[i,1],
                                  nodesize = hyperparameter_grid[i,2],
                                  sampsize = floor(hyperparameter_grid[i,3])) # it's mandatory you round the sample size here to an integer, otherwise the predict() code will break
                                  rf_list[[i]] <- rf
        }
        return(rf_list)
}

class_rf_list <- run_class_rf(balanced_train_list,best_hyper_all)
```

Examine overall OOB rate
```{r}
set.seed(8976969)
#' @rf_list: list containing all rf models
mean_OOB <- function(rf_list) {
        OOB_list <- numeric(length = length(rf_list)) #empty holder vector to hold all the OOBs
        for (i in 1:length(rf_list)){
            err <- as.data.frame(rf_list[[i]]$err.rate) 
            OOB <- mean(err$OOB) #mean OOB for each model
            OOB_list[[i]] <- OOB
        }
        return(OOB_list)
}

mean_OOB_list <- mean_OOB(class_rf_list) #OOB values for all classification RF models
mean(mean_OOB_list) #average of all OOB values
hist(mean_OOB_list)#visualize distribution of OOB values 

 #print(rf1) #use this print out individual RF model 
 #varImpPlot(rf1) #use this to plot the importance for predictor columns
```


##Predict the test set
```{r}
set.seed(57835678)
#' @rf_list: list of random forest models from bootstrapping
class_rf_pred <- function(rf_list, test_data){
        for (i in 1:length(rf_list)){
                test_data <- cbind(test_data,predict(object = rf_list[[i]],newdata = test_data,type = "class")) #attach all the prediction results for every bootstrapp to the test data
        } 
        return(test_data)
}
gwide_test_CGC_new <- class_rf_pred(class_rf_list,gwide_test_CGC)
```

Rank the genes based on the frequency of being predicted as TS(1)
```{r}
#convert all prediction result columns to numeric, for addition
for (i in 34:133) {
        gwide_test_CGC_new[,i] <- as.numeric(gwide_test_CGC_new[,i])
        
}

#add all prediction result for all bootstrapped samples, and store this summation in a columns
gwide_test_CGC_new$hits_total <- rowSums(gwide_test_CGC_new[,34:133]) 

rf_class_result <- as.data.frame(rowSums(gwide_test_CGC_new[,34:133])) 
colnames(rf_class_result) = "TS_freq"
rf_class_result <- rownames_to_column(rf_class_result,var = "Gene")
rf_class_result <- rf_class_result[order(rf_class_result$TS_freq,decreasing = TRUE),]
rf_class_result #this is the list of TSs, ranked by their total frquency, predicted by a bootstrapped sampling(100 times) of classification random forest

#export the predicted hits
write.csv(rf_class_result, "/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/pred_hits_CGC_bootstrap.csv")
```


Examine overlaps
```{r}
#overlapping between CGC labeled TS and the predicted TS
high_conf_hits <- as.data.frame(rf_class_result$Gene[1:110][rf_class_result$Gene[1:110] %in% CGC_TS$Gene])
high_conf_hits

#overlapping between Jeremy's 96 genes with the predicted TS
jeremy_genes_overlap <- as.data.frame(rf_class_result$Gene[1:110][rf_class_result$Gene[1:110] %in% jeremy_genes$Gene])
jeremy_genes_overlap
#29 overlaps

#import the predicted result using only one sampling(no bootstrapping)
pred_gene <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/pred_hits_CGC.csv",stringsAsFactors = FALSE)

as.data.frame(rf_class_result$Gene[1:110][rf_class_result$Gene[1:110] %in% pred_gene$Gene])
```


Performance measures:
We will perform performance measures on both training and testing data

Calculate the average performance metrics from all confusion matrix
```{r,fig.width=18,fig.height=7}
#training data
#class_rf_list is the list that contains our 100 bootstrapped RF models, we will calculate the average of each element in all of the confusion matrix
rf_sample <- class_rf_list[[2]]
rf_sample$confusion %>% length()

#calculate accuracy, precision, sensitivity and specificity for every bootstrapped confusion matrix and average them
#initialize empty holder vectors
accuracy <- vector()
precision <- vector()
sensitivity <- vector()
specificity <- vector()
for (i in 1:length(class_rf_list)) {
  conf <- class_rf_list[[i]]$confusion
  accuracy <- c(accuracy,(conf[1] + conf[4])/(conf[1]+conf[2] + conf[3] + conf[4]))
  precision <- c(precision,conf[4]/(conf[3] + conf[4]))
  sensitivity <- c(sensitivity,conf[4]/(conf[2] + conf[4]))
  specificity <- c(specificity, conf[1]/(conf[1] + conf[3]))
}

#calculate the mean of these performance metrics
mean(accuracy)
mean(precision)
mean(sensitivity)
mean(specificity)
```

Importance of predictor variables
```{r,fig.width=10,fig.height=7}
#calculate the average of mean decreases accuracy and mean decreased Gini Index
#empty holder df for mean decreased accuracy
mda <- rownames(importance(class_rf_list[[1]])) %>% 
  as.data.frame() %>%
  rename(predictor = ".")

#for mean decreased gini index
mdg <- rownames(importance(class_rf_list[[1]])) %>% 
  as.data.frame() %>%
  rename(predictor = ".")

for (i in 1:length(class_rf_list)){
     imp <- importance(class_rf_list[[i]]) %>%
       as.data.frame()
     mda <- c(mda,imp[3]) %>% as.data.frame()
     mdg <- c(mdg,imp[4]) %>% as.data.frame()
}


#calculate the average for each predictors
mda <- mutate(mda,mean_decreased_accuracy = rowMeans(mda[2:101]))
mdg <- mutate(mdg,mean_decreased_gini = rowMeans(mdg[2:101]))

#change the name of the predictors to the correct format
pred_names <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/gwide_dup_rm_knn.csv",header = FALSE)
pred_names <- pred_names[1,2:33]
pred_names <- as.character(pred_names)

mda[1] <- pred_names
mdg[1] <- pred_names
#plot mean decreased accuracy
mda %>%
  dplyr::arrange(desc(mean_decreased_accuracy)) %>%
  ggplot(aes(reorder(predictor,mean_decreased_accuracy),mean_decreased_accuracy)) +
  geom_col() +
  coord_flip() +
  labs(title = "Mean Descrease in Accuracy") +
  xlab("Predictors")+
  theme_classic() +
  theme(axis.text = element_text(size = 10,face = "bold"),
        axis.title = element_text(size = 15, face = "bold"),
        title = element_text(size = 15, face = "bold"))

ggsave("/Users/weihan/Documents/GitHub/ts_machine_learning/data/Final_Figures/mean_dec_accuracy.jpg",dpi = 600,units = "in",height = 7,width =10)

#plot mean decreased gini
mdg %>%
  dplyr::arrange(desc(mean_decreased_gini)) %>%
  ggplot(aes(reorder(predictor,mean_decreased_gini),mean_decreased_gini)) +
  geom_col() +
  coord_flip() +
  labs(title = "Mean Descrease in Gini Index") +
  xlab("Predictors")+
  theme_classic() +
  theme(axis.text = element_text(size = 10,face = "bold"),
        axis.title = element_text(size = 15, face = "bold"),
        title = element_text(size = 15, face = "bold"))

ggsave("/Users/weihan/Documents/GitHub/ts_machine_learning/data/Final_Figures/mean_dec_gini.jpg",dpi = 600,units = "in",height = 7,width =10)
```


AUC and ROC curve on training set
```{r}
library(pROC)
rf_sample$votes

rf.roc<-roc(balanced_train_list[[2]]$TS_status,rf_sample$votes[,2])
plot(rf.roc)
auc(rf.roc)

#calculate the average vote for each gene in the training data set
vote <- gwide_train_CGC$Gene %>% 
  as.data.frame() %>%
  rename(Gene = ".")
for (i in 1:length(class_rf_list)) {
  #convert votes for each bootstrapped rf sample to a dataframe
  bs_vote <- as.data.frame(class_rf_list[[i]]$votes)
  bs_vote <- rownames_to_column(bs_vote,var = "Gene")
  bs_vote <- bs_vote[,-2]
  vote <- full_join(vote,bs_vote,by = "Gene")
}

#plot the ROC curve

library(pROC)
pROC_obj <- roc(gwide_train_CGC$TS_status,vote$avg_vote,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.90, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
## Warning in plot.ci.se(sens.ci, type = "shape", col = "lightblue"): Low
## definition shape.
plot(sens.ci, type="bars")

#define a function to save the image
save_jpeg <- function(x, filename, width=7, height=7,res = 300) {
   stopifnot(!missing(x))
   stopifnot(!missing(filename))
   jpeg(filename, width=width, height=height,res = res,units = "in")
   grid::grid.newpage()
   grid::grid.draw(x$gtable)
   dev.off()
}
save_jpeg(p,"/Users/weihan/Documents/GitHub/ts_machine_learning/data/Final_Figures/roc.jpg",7,7,600)
```








