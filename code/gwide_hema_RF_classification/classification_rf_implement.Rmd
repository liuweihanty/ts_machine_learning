---
title: "gwide_random_forest_implementation"
author: "Weihan Liu"
date: "17/02/2020"
output: html_document
---

##Install relevant packages
```{r,results='hide'}
library(randomForest)  #ML
library(caret)  #ML
library(ggplot2) #plotting
library(dplyr) #data manipulation
library(tibble) #data manipulation
library(stats) #data manipulation
```


##Read in files
```{r}

gwide_knn <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/gwide_dup_rm_knn.csv") 
str(gwide_knn)
```

some data cleaning
```{r}
set.seed(1278353)
#move the gene column to row names
gwide_knn <- gwide_knn %>% column_to_rownames(var = "Gene")
gwide_knn <- select(gwide_knn, -"X")
head(gwide_knn)
```


Content below are for non-bootstrapped version, We decided to use bootstrapping, so skip this section plz
-----------------------------------------------------------------------------------------

split for testing and training data, training data are every gene not on chr 7, tetsing data are everything on chr7
```{r}
#split for testing and training data, training data are every gene not on chr 7, tetsing data are everything on chr7
table(gwide_knn$chromosome)

#create training data (unbalanced)
gwide_train <- gwide_knn %>%
        filter(chromosome != 7 & chromosome != "MT")

table(gwide_train$chromosome)
```

there are 17484 non-TS and 943 TS, which caused the problem of classification imbalance. The majority 0s will dominate the training process, thus, we need to make a more balanced training set in terms of the TS label. from the gwide_train table, I extracted all the TSs(~1000 genes) and from the non-TSs, I randomly sampled ~ 1000 genes, and combined these two sets of genes.
```{r}
#create a balanced training set by taking all TSGene == 1(tumor suppressors), and sample randomly from each chromosome by fraction = 0.06. In this way, in the final training set we will have roughly equal amount of TS and non-TS
gwide_train_balance <- filter(gwide_train,TS_status == 0) %>% 
        grouped_df("chromosome") %>%
        sample_frac(size = 0.06)

gwide_train_balance <- as.data.frame(gwide_train_balance)
gwide_train_balance <- rbind(gwide_train_balance,filter(gwide_train,TS_status == 1))
str(gwide_train_balance)

gwide_train_balance$TS_status <- as.factor(gwide_train_balance$TS_status)

#creating testing set, which will be all genes on chromosome 7
gwide_test <- gwide_knn %>%
        filter(chromosome == 7)
gwide_test$TS_status <- as.factor(gwide_test$TS_status)
glimpse(gwide_test)

table(gwide_train_balance$TS_status)
```


##Hyperparameter tuning
```{r}
#' @ntree: number of trees, default is 500
#' @mtry: number of variables randomly sampled as candidates at each split
#' @samplesize: number of samples(rows) to train on, default = 63.2%
#' @nodesize: minimum size(# of samples) pf the terminal nodes, if small, allows deeper and more complex tree
#' @maxnodes: maximum number of terminal nodes

#grid search
# Establish a list of possible values for mtry, nodesize and sampsize
mtry <- seq(4, ncol(gwide_train_balance) * 0.8, 2)
nodesize <- seq(3, 10, 2)
sampsize <- nrow(gwide_train_balance) * c(0.7,0.8)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
    rf_model <- randomForest(formula = TS_status ~ ., 
                          data = select(gwide_train_balance,-c("chromosome")),
                          mtry = hyper_grid$mtry[i],
                          nodesize = hyper_grid$nodesize[i],
                          sampsize = hyper_grid$sampsize[i])
                          
    # Store OOB error for the model                      
    oob_err[i] <- rf_model$err.rate[nrow(rf_model$err.rate), "OOB"]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
```



## fit of random forest model using the optimal hyperparameters
```{r, fig.height=4, fig.width=8}
set.seed(22)
#taking the 
rf = randomForest(TS_status ~ .,  
                   data = select(gwide_train_balance,-c("chromosome")),importance = TRUE,mtry = 4,nodesize = 9,sampsize = 0.8*nrow(gwide_train_balance))
plot(rf) 
print(rf)
varImpPlot(rf)

```


##Predict the test set
```{r}
# Generate predicted classes using the model object
gwide_test$class_prediction <- predict(object = rf,   # model object 
                            newdata = gwide_test,  # test dataset
                            type = "class") 

#extract the predicted TS genes in the test set
pred_gene <- filter(gwide_test, class_prediction == 1)["Gene"]

#read in the TSGene data
tsgene <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/TSGene_all.csv",stringsAsFactors = FALSE)
#overlapping between TSGene TS and the overlapping gene between 96 TS + predicted ts(our targets)
high_conf_hits <- as.data.frame(pred_gene$Gene[pred_gene$Gene %in% tsgene$GeneSymbol])

write.csv(high_conf_hits,"/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/high_conf_hits_TSGene.csv")
```

Check the overlap between Jeremy's datamining 96 TS with the canonical TS
```{r}
jeremy_ts <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/96ts_work_data.csv")
jeremy_genes <- jeremy_ts["Gene"]
jeremy_genes$Gene <- as.character(jeremy_genes$Gene)


#overlap between Jelemy's datamining 96 TS and the TSGene database canonical TS
hits <- c()
for (i in 1:length(jeremy_genes$Gene)) {
        if (jeremy_genes$Gene[i] %in% as.character(pred_gene$Gene)){
                hits <- c(hits,jeremy_genes$Gene[i])
        }
      
}
hits #list of Jeremy dataminning 96 TS that overlap with the RF predicted genes

#overlapping between TSGene TS and the overlapping gene between 96 TS + predicted ts(our targets)
pred_gene$Gene[pred_gene$Gene %in% canonical_ts_chr7$Gene]

```

Our hit genes: overlap between predicted chr7 TS and Jeremy's screen genes
 [1] "HNRNPA2B1" "IKZF1"     "YWHAG"     "EIF2AK1"   "KMT2C"     "MCM7"      "KMT2E"     "PTPN12"    "TNRC18"    "AHR"      
[11] "GRB10"     "LUC7L2"    "CASP2"     "CUX1"      "LIMK1"     "IGF2BP3"   "EZH2"      "PLOD3"     "IRF5"      "AGK"      
[21] "JAZF1"     "BCAP29"    "SP4"       "ZNF12"     "ASL"       "PHF14"     "TMEM120A"  "ZNF800"    "PAXIP1"    "ATXN7L1"  
[31] "GNAI1"     "ZSCAN25"   "ZNF467"    "NRF1"      "KCTD7"     "HOXA10"    "CLDN15"    "BRAF"      "ZC3HAV1L"  "ZNF789"   
[41] "PUS7"      "BPGM"      "PTCD1"     "WASL"      "VKORC1L1"  "STX1A"     "AP4M1"     "SEMA3C"    "SMO"       "GTF2IRD1"

The overlap of above with TSGene labeled TS:
 "IKZF1"  "KMT2C"  "PTPN12" "AHR"    "CASP2"  "CUX1"   "EZH2"   "IRF5"   "NRF1" 

##Evaluate the model performance on test set
```{r}

# Calculate the confusion matrix for the test set
cm <- confusionMatrix(data = as.factor(class_prediction),       # predicted classes
                      reference = gwide_test$TS_status)  # actual classes

print(cm)


#AUC of test set
library(pROC)
# Generate predictions on the test set
pred <- predict(object = rf,
            newdata = gwide_test,
            type = "prob")


# Compute the AUC (`actual` must be a binary 1/0 numeric vector)
auc(actual = ifelse(gwide_test$TS_status == 1, 1, 0), 
    predicted = pred[,1])     
```



-----------------------------------------------------------------------------------------------


Use the label from Cancer Gene Census as the ground truth instead of the TSGene
##Read in the data and switch the ground truth column
```{r}
#read in the CGC data
CGC_TS <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/GCG_TS.csv",stringsAsFactors = FALSE)
CGC_TS <- CGC_TS$Gene.Symbol 
CGC_TS <- as.data.frame(CGC_TS)
CGC_TS <- CGC_TS %>% mutate("TS_status" = 1) %>% rename(Gene = CGC_TS)

gwide_knn <- rownames_to_column(gwide_knn, var = "Gene")
#switch the ground truth column from TSGene to CGC
gwide_knn_CGC <- gwide_knn %>% select(-TS_status) %>%
        full_join(CGC_TS, by = "Gene")
#replace all the NAs in the TS_status columns with 0s
gwide_knn_CGC$TS_status[is.na(gwide_knn_CGC$TS_status)] <- 0

glimpse(gwide_knn_CGC)

```


##Split the training vs testing data
create training data, which is all of the non-chromosome 7 genes. The training data is unbalanced, majority of genes are non CGC labeled TS, so their TS status = 0
```{r}
gwide_train_CGC <- gwide_knn_CGC %>%
        filter(chromosome != 7 & chromosome != "MT")

table(gwide_train_CGC$chromosome)
```

Balance the training data set by sampling non-TS from the training data set using bootstrapping
```{r}
set.seed(683723)

#function to generate the balanced training data
# input is the unbalanced unsampled training data
train_data_generate <- function(train_data = gwide_train_CGC){

        gwide_train_balance_CGC <- filter(train_data,TS_status == 0) %>% 
                                grouped_df("chromosome") %>%
                                sample_frac(size = 0.02)
                        
        gwide_train_balance_CGC <- as.data.frame(gwide_train_balance_CGC)
        gwide_train_balance_CGC <- rbind(gwide_train_balance_CGC,filter(gwide_train_CGC,TS_status == 1))
        gwide_train_balance_CGC$TS_status <- as.factor(gwide_train_balance_CGC$TS_status)
        gwide_train_balance_CGC <- column_to_rownames(gwide_train_balance_CGC,var = "Gene")
        
        return(gwide_train_balance_CGC )
}


#run the function 100 times and store the resulted training data in a list
balanced_train_list  <- lapply(seq_len(100),function(x) train_data_generate(gwide_train_CGC))

```

Generate testing data
```{r}
#creating testing set, which will be all genes on chromosome 7
gwide_test_CGC <- gwide_knn_CGC %>%
        filter(chromosome == 7)
gwide_test_CGC$TS_status <- as.factor(gwide_test_CGC$TS_status)
gwide_test_CGC <- select(gwide_test_CGC, -"chromosome")
gwide_test_CGC <- column_to_rownames(gwide_test_CGC,var = "Gene")

str(gwide_test_CGC)

```


training data list: balanced_train_list
testing data: gwide_test_CGC

##Hyperparameter tuning
We will use a grid search based method to exhaustively search for the best combination hyperparameters, which will give the smallest OOB error
```{r}
#' @ntree: number of trees, default is 500
#' @mtry: number of variables randomly sampled as candidates at each split
#' @samplesize: number of samples(rows) to train on, default = 63.2%
#' @nodesize: minimum size(# of samples) pf the terminal nodes, if small, allows deeper and more complex tree
#' @maxnodes: maximum number of terminal nodes

#grid search
#Establish a list of possible values for mtry, nodesize and sampsize
mtry <- seq(4, ncol(balanced_train_list[[1]]) * 0.8, 2)
nodesize <- seq(3, 10, 2)
sampsize <- nrow(balanced_train_list[[1]]) * c(0.7,0.8)
#create an empty holder dataframe to hold all the hyperparatmeters creates for each boostrap

best_hyper_all <- data.frame()

hyper_parameter_tune <- function(train_data,mtry,nodesize,sampsize){
        for (k in 1:length(train_data)){
                # Create a data frame containing all combinations 
                hyper_grid <- expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
                # Create an empty vector to store OOB error values
                oob_err <- c()
                
                # Write a loop over the rows of hyper_grid to train the grid of models
                for (i in 1:nrow(hyper_grid)) {
                
                    # Train a Random Forest model
                    rf_model <- randomForest(formula = TS_status ~ ., 
                                          data = select(train_data[[k]],-c("chromosome")),
                                          mtry = hyper_grid$mtry[i],
                                          nodesize = hyper_grid$nodesize[i],
                                          sampsize = hyper_grid$sampsize[i])
                                          
                    # Store OOB error for the model                      
                    oob_err[i] <- rf_model$err.rate[nrow(rf_model$err.rate), "OOB"]
                }
        
                # Identify optimal set of hyperparmeters based on OOB error
                opt_i <- which.min(oob_err)
                best_hyper <- hyper_grid[opt_i,]
                best_hyper_all <- rbind(best_hyper_all,best_hyper) 
        }
       return(best_hyper_all)        
}  

best_hyper_all <- hyper_parameter_tune(balanced_train_list,mtry,nodesize,sampsize) 
 
```


## fit of random forest model using the optimal hyperparameters
```{r, fig.height=4, fig.width=8}
set.seed(2245646)
#' @train_data_list: list of randomly sampled training data
#' @hyperparameter_grid: a dataframe of hyperparameteers corresponding to your training data list. Each training data in the list has a corresponding combination of hyperparameters


run_class_rf <- function(train_data_list = balanced_train_list,hyperparameter_grid = best_hyper_all) {
        rf_list <- vector(mode = "list",length = length(balanced_train_list)) #empty holder list to hold all the rf model 
        for (i in 1:length(train_data_list)) {
                rf = randomForest(TS_status ~ .,
                                  data = select(train_data_list[[i]],
                                   -"chromosome"),
                                  importance = TRUE,
                                  mtry = hyperparameter_grid[i,1],
                                  nodesize = hyperparameter_grid[i,2],
                                  sampsize = floor(hyperparameter_grid[i,3])) # it's mandatory you round the sample size here to an integer, otherwise the predict() code will break
                                  rf_list[[i]] <- rf
        }
        return(rf_list)
}

class_rf_list <- run_class_rf(balanced_train_list,best_hyper_all)
```

Examine overall OOB rate
```{r}
set.seed(8976969)
#' @rf_list: list containing all rf models
mean_OOB <- function(rf_list) {
        OOB_list <- numeric(length = length(rf_list)) #empty holder vector to hold all the OOBs
        for (i in 1:length(rf_list)){
            err <- as.data.frame(rf_list[[i]]$err.rate) 
            OOB <- mean(err$OOB) #mean OOB for each model
            OOB_list[[i]] <- OOB
        }
        return(OOB_list)
}

mean_OOB_list <- mean_OOB(class_rf_list) #OOB values for all classification RF models
mean(mean_OOB_list) #average of all OOB values
boxplot(mean_OOB_list)#visualize distribution of OOB values 

 #print(rf1) #use this print out individual RF model 
 #varImpPlot(rf1) #use this to plot the importance for predictor columns
```


##Predict the test set
```{r}
set.seed(57835678)
#' @rf_list: list of random forest models from bootstrapping
class_rf_pred <- function(rf_list, test_data){
        for (i in 1:length(rf_list)){
                test_data <- cbind(test_data,predict(object = rf_list[[i]],newdata = test_data,type = "class")) #attach all the prediction results for every bootstrapp to the test data
        } 
        return(test_data)
}
gwide_test_CGC_new <- class_rf_pred(class_rf_list,gwide_test_CGC)

```

Rank the genes based on the frequency of being predicted as TS(1)
```{r}
#convert all prediction result columns to numeric, for addition
for (i in 34:133) {
        gwide_test_CGC_new[,i] <- as.numeric(gwide_test_CGC_new[,i])
        
}

#add all prediction result for all bootstrapped samples, and store this summation in a columns
gwide_test_CGC_new$hits_total <- rowSums(gwide_test_CGC_new[,34:133]) 

rf_class_result <- as.data.frame(rowSums(gwide_test_CGC_new[,34:133])) 
colnames(rf_class_result) = "TS_freq"
rf_class_result <- rownames_to_column(rf_class_result,var = "Gene")
rf_class_result <- rf_class_result[order(rf_class_result$TS_freq,decreasing = TRUE),]
rf_class_result #this is the list of TSs, ranked by their total frquency, predicted by a bootstrapped sampling(100 times) of classification random forest

#export the predicted hits
write.csv(rf_class_result, "/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/pred_hits_CGC_bootstrap.csv")
```


Examine overlaps
```{r}
#overlapping between CGC labeled TS and the predicted TS
high_conf_hits <- as.data.frame(rf_class_result$Gene[1:110][rf_class_result$Gene[1:110] %in% CGC_TS$Gene])
high_conf_hits

#overlapping between Jeremy's 96 genes with the predicted TS
jeremy_genes_overlap <- as.data.frame(rf_class_result$Gene[1:110][rf_class_result$Gene[1:110] %in% jeremy_genes$Gene])
jeremy_genes_overlap
#29 overlaps

#import the predicted result using only one sampling(no bootstrapping)
pred_gene <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/pred_hits_CGC.csv",stringsAsFactors = FALSE)

as.data.frame(rf_class_result$Gene[1:110][rf_class_result$Gene[1:110] %in% pred_gene$Gene])
```


plot the ROC curve
```{r}
library(pROC)
pROC_obj <- roc(as.numeric(gwide_test_CGC$TS_status),as.numeric(gwide_test_CGC$hits),
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
## Warning in plot.ci.se(sens.ci, type = "shape", col = "lightblue"): Low
## definition shape.
plot(sens.ci, type="bars")


```






