---
title: "gene_vs_screen_presence"
author: "Weihan Liu"
date: "18/05/2020"
output: html_document
---

Plot all 96 genes from Jeremy's datamining efforts vs all the screens he used.

Goal:
1).visualzie the genes that are identified to be putative TS by the most screens
2).Determine which screen contributes the most to datamining

```{r}
library(pheatmap)
```

```{r}
gene_vs_screen <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/summary_analysis/gene_vs_screen_presence.csv",stringsAsFactors = FALSE) %>%
        dplyr::select(-c("X")) %>%
        dplyr::rename(apperance = X..of.screens) %>%
        arrange(desc(apperance))
        
#replace all "Yes" with 1 and all other cells with 0
gene_vs_screen[,2:14] <- ifelse(gene_vs_screen[,2:14] == "Yes",1,0)
gene_vs_screen <- column_to_rownames(gene_vs_screen,var = "Gene")     

str(gene_vs_screen)

#Examine which screen has the highest number of genes 
as.data.frame(colSums(gene_vs_screen)) %>%
                                                rownames_to_column(var = "screen") %>%
                                                arrange(desc(colSums(gene_vs_screen)))
#order the columns in the dataframe by their colsums, descending order.(for plottig)
gene_vs_screen <- gene_vs_screen[,c("Weissman.2016","Elledge.2018",
                  "Wallace.2016","Doench.2018",
                  "Sabatini.2015.GTS","Elledge.2013",
                  "GCG",
                  "Sabatini.2015","Weissman.2014",
                  "Campbell.2018","Sabatini.2017",
                  "Chen.2019","Brummelkamp.2015","apperance")]
```

Plot heatmap
```{r,fig.height=18,fig.width=15}
pheatmap(as.matrix(gene_vs_screen[1:13]),
        scale = "none",
        cexRow = 0.3,cexCol = 3,
        cellwidth = 50,
        cellheight = 11,
         color = c("#d7ebff","#ffd452"),
         #color = c("#ffe4d8","#ff5e4f"), deep and shallow red  
        # color = c("#EBF6FF","#64aaff"),  #deep and shallow blue                
        #border_color = "black",
        cluster_cols = FALSE,
        cluster_rows = FALSE,
        treeheight_col = 0, #get rid of the dendrogram
        legend_breaks = c(0,1),
        legend_labels = c("absent in screen","present in screen"),
        fontsize_col = 20,
        angle_col = 45)


```



Grand Heatmap:

1).continuous variables:
Proliferation score, 
Erythroid differentiation impairment score
Combined experimental score
z scores on all CRISPR screens we used
Machine Learning score

2.).categorical variables
Cancer Gene Census TS status
CDR status

read in all the predictor columns
```{r}
rf_predictors <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/gwide_dup_rm_knn_CGC.csv",stringsAsFactors = FALSE)
#only retain the crispr score and gene name columns
rf_predictors <- select(rf_predictors,-c("chromosome","TS_status"))
```

revert sings of activation/over expression screens so that higher positive values means more TS like
```{r}
#different scoring systems will rank tumor suppresiveness like traits in different directions, for example, in CRISPR KO screen, a more positive score means more TS like, while in CRISPRa screen, a more negative score means more TS like. Like unify the sign here so that a higher, more positive z score indicates TS. So let's revert the signs of CRISPRa and over expression screens
rf_predictors$Gilbert.2014.CRISPRa.Growth.phenotype.mean <- -rf_predictors$Gilbert.2014.CRISPRa.Growth.phenotype.mean
rf_predictors$Sanson.2018.Average.LFC <- -rf_predictors$Sanson.2018.Average.LFC
rf_predictors$Sack.2019.HMEC.Average.Log2FC.Drop <- -rf_predictors$Sack.2019.HMEC.Average.Log2FC.Drop
rf_predictors$Sack.2019.HPNE.Average.Log2FC.Drop <- -rf_predictors$Sack.2019.HPNE.Average.Log2FC.Drop
rf_predictors$Horlbeck.2016.CRISPRa.average.phenotype.of.strongest <- -rf_predictors$Horlbeck.2016.CRISPRa.average.phenotype.of.strongest
```

calculate the z score of crispr screen columns based on all the genes. Later we will also calculate the z scores just on the 100+ genes we are presenting
```{r}
z_score <- function(x){
        (x - mean(x))/sd(x)
}

#examine how many NA values each colum has
apply(rf_predictors[2:ncol(rf_predictors)],2,is.na) %>% apply(2,sum)
#examine which gene contains NA values
rf_predictors[is.na(rf_predictors$Blomen.2015.hap1.GTS.ratio),]
#get rid of the gene contains NA value
rf_predictors <- filter(rf_predictors,Gene != "MALAT1")
#make a copy of the rf_predictors to store z scores calculate on all genes
rf_predictors_z_all <- rf_predictors
#calculate z scores for each column
rf_predictors_z_all[2:ncol(rf_predictors_z_all)] <- apply(rf_predictors_z_all[2:ncol(rf_predictors_z_all)], 2, z_score) 
str(rf_predictors_z_all)
```


Read in classification machine learning score
```{r}
rf_class_result <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/pred_hits_CGC_bootstrap.csv",stringsAsFactors = FALSE)

#version with bootstrapped ML
rf_class_result <-  dplyr::select(rf_class_result,-"X") 

#create a binary version of rf_class_result result, the one above contains the bootstrapped score
#extract the genes with a ML socre of more than 150.(range of score is 100-200) These are the genes that are predicted to be TS in more than half of the times
rf_class_result_150_more <- filter(rf_class_result,TS_freq >= 150) %>% 
                         select(-"TS_freq") %>%
                         mutate(RF_status = 1)
        
str(rf_class_result_150_more)
```


Proliferation score, 
Erythroid differentiation impairment score
Combined experimental score
```{r}
exp_score <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/z_value_calc/comb_ranking.csv",stringsAsFactors = FALSE)
exp_score <- select(exp_score,c("Gene","avg.pro","avg.ery","avg_comb"))
str(exp_score)
```

CGC status
```{r}
CGC_status <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/gwide_hema_classification/GCG_TS.csv",stringsAsFactors = FALSE)
CGC_status <- select(CGC_status,"Gene.Symbol") %>% 
        rename(Gene = Gene.Symbol) %>% mutate(CGC_TS = 1)
```

CDR status
```{r}
CDR_status <- read.csv("/Users/weihan/Documents/GitHub/ts_machine_learning/data/CDR_list.csv",stringsAsFactors = FALSE,header = FALSE)
names(CDR_status) <- "Gene"
CDR_status <- mutate(CDR_status,CDR_status = 1)
```
Combine everything together, note we will only plot the genes used in experiment

for random forest result we have two versions
rf_class_result: with bootstrapped score
rf_class_result_150_more: the genes whose bootstrapped score above 150, and with a binary column indicating Yes/No

Let's use the bootstrapped score, and create two versions, 
version 1: all the ML predictor columns their z score are only calculated on the 100 + genes presented in the heatmap
version 2: all the ML predictor columns their z score calculated on all genes in their initial data set
```{r,}
#the version 1 
grand_sheet <- left_join(exp_score,rf_predictors,by = "Gene") %>% 
        left_join(rf_class_result, by = "Gene") %>%
        left_join(CGC_status, by = "Gene") %>%
        left_join(CDR_status, by = "Gene")
#convert the NAs in CGC status and CDR status to 0
grand_sheet$CGC_TS[is.na(grand_sheet$CGC_TS)] <- 0
grand_sheet$CDR_status[is.na(grand_sheet$CDR_status)] <- 0
#convert the NAs in the TS_fre(ML bootstrapped score column) into 100, which is equivalent to 0
grand_sheet$TS_freq[is.na(grand_sheet$TS_freq)] <- 100
#delete control genes AAVS1,GATA1,PTEN, Mock
grand_sheet <- filter(grand_sheet,!(Gene %in% c("AAVS1","GATA1","PTEN","Mock")))
#relocate columns to leave all the crispr screen data to the ;later half
grand_sheet <- grand_sheet %>% 
                      relocate(c("CDR_status","CGC_TS","TS_freq"),.after = avg_comb)

#the version 2 
grand_sheet_2 <- left_join(exp_score,rf_predictors_z_all,by = "Gene") %>% 
        left_join(rf_class_result, by = "Gene") %>%
        left_join(CGC_status, by = "Gene") %>%
        left_join(CDR_status, by = "Gene")

#convert the NAs in CGC status and CDR status to 0
grand_sheet_2$CGC_TS[is.na(grand_sheet_2$CGC_TS)] <- 0
grand_sheet_2$CDR_status[is.na(grand_sheet_2$CDR_status)] <- 0
#convert the NAs in the TS_fre(ML bootstrapped score column) into 100, which is equivalent to 0
grand_sheet_2$TS_freq[is.na(grand_sheet_2$TS_freq)] <- 100
#delete control genes AAVS1,GATA1,PTEN, Mock
grand_sheet_2 <- filter(grand_sheet_2,!(Gene %in% c("AAVS1","GATA1","PTEN","Mock")))
#relocate columns to leave all the crispr screen data to the ;later half
grand_sheet_2 <- grand_sheet_2 %>% 
                      relocate(c("CDR_status","CGC_TS","TS_freq"),.after = avg_comb)
```



Impute missing values
```{r}
#Version 1
# test which column has missing values
apply(grand_sheet,2,is.na) %>% apply(2,sum)
#make a duplivate copy for calculating z scores
grand_sheet_z <- grand_sheet

#Version 2
# test which column has missing values
apply(grand_sheet_2,2,is.na) %>% apply(2,sum)
#make a duplivate copy for calculating z scores
grand_sheet_2_z <- grand_sheet_2
```


Calculate z scores

For the predictor columns used in ML, we will try to calculate their z score using two methods:
Version 1(grand_sheet_z): Just calculate their z score within the group of genes we are plotting. So calculation of z scores for these predictors will be together with all other columns in the grand sheet

Version 2(grand_sheet_2_z):calculating their z score based on their original screen complete data.I already calculated the z scores for all the ML variables based on all the genes in their initial screen, so all left are just calculating the z scores for the rest of the columns seperately.
```{r}
#Version 1
#we will divide the heat map to two parts and plot, the first part is the binary columns:
grand_sheet_z_binary <- select(grand_sheet_z,c("Gene","CDR_status","CGC_TS")) %>%
        column_to_rownames(var = "Gene")
#the second is the continuous columns:
grand_sheet_z_cont <- select(grand_sheet_z,-c("CDR_status","CGC_TS")) %>%
        column_to_rownames(var = "Gene")
#convert the continuous dataframe to z scores
z_score <- function(x){
        (x - mean(x))/sd(x)
}
grand_sheet_z_cont <- as.data.frame(apply(grand_sheet_z_cont,2,z_score))

#Version 2
#we will divide the heat map to two parts and plot, the first part is the binary columns:
grand_sheet_2_z_binary <- select(grand_sheet_2_z,c("Gene","CDR_status","CGC_TS")) %>%
        column_to_rownames(var = "Gene")
#the second is the continuous columns:
grand_sheet_2_z_cont <- select(grand_sheet_2_z,-c("CDR_status","CGC_TS")) %>%
        column_to_rownames(var = "Gene")
str(grand_sheet_2_z_cont)
#convert the continuous dataframe to z scores, note only convert the first 4 columns,the rest are ML predictor columns which are already z scorss based on all the genes in the initial screen
z_score <- function(x){
        (x - mean(x))/sd(x)
}
grand_sheet_2_z_cont[1:4] <- as.data.frame(apply(grand_sheet_2_z_cont[1:4],2,z_score))
```


Devise a ranking schematic that equally weights three columns and produce a ranking order:
1.ML score
2.experimental combined score
3.CDR status
```{r ranking}
#Version 1
#combine the continuous and binary df into one
grand_sheet_z_all <- cbind(grand_sheet_z_cont,grand_sheet_z_binary)
str(grand_sheet_z_all)

#min max normalize the ML score and experimental combined score columns so that their values are linearly transformed to fall on the range of (0,1). Note the data are already in z score, so we don't need to worry about outliers
min_max_norm <- function(x){
      (x - min(x))/(max(x) - min(x))  
}
grand_sheet_z_all$TS_freq_MM <- min_max_norm(grand_sheet_z_all$TS_freq)
grand_sheet_z_all$avg_comb_MM <- min_max_norm(grand_sheet_z_all$avg_comb)

#now, the binary CDR status column is either 0, or1, and the min-max transformed TF_Freq and avg_comb scores are also on the range of (0,1), we can assume they are on the same scale
grand_sheet_z_all$sort <- grand_sheet_z_all$TS_freq_MM +
        grand_sheet_z_all$avg_comb_MM +
        grand_sheet_z_all$CDR_status

density(grand_sheet_z_all$sort) %>% plot()    

#bind the sorting column back to grand_sheet_z_cont and grand_sheet_z_binary, and sort them according to the sort column
grand_sheet_z_cont <- cbind(grand_sheet_z_cont,grand_sheet_z_all$sort)
grand_sheet_z_cont <- rename(grand_sheet_z_cont,sort = "grand_sheet_z_all$sort")
grand_sheet_z_cont <- grand_sheet_z_cont[order(grand_sheet_z_cont$sort,decreasing = TRUE),]
#change the TS_Freq to ML_score
grand_sheet_z_cont <- grand_sheet_z_cont %>% rename(ML_score = TS_freq)

grand_sheet_z_binary <- cbind(grand_sheet_z_binary,grand_sheet_z_all$sort) %>%
        rename(sort = "grand_sheet_z_all$sort")

grand_sheet_z_binary <- grand_sheet_z_binary[order(grand_sheet_z_binary$sort,decreasing = TRUE),]

#Version 2
#combine the continuous and binary df into one
grand_sheet_2_z_all <- cbind(grand_sheet_2_z_cont,grand_sheet_2_z_binary)
str(grand_sheet_2_z_all)

#min max normalize the ML score and experimental combined score columns so that their values are linearly transformed to fall on the range of (0,1). Note the data are already in z score, so we don't need to worry about outliers
min_max_norm <- function(x){
      (x - min(x))/(max(x) - min(x))  
}
grand_sheet_2_z_all$TS_freq_MM <- min_max_norm(grand_sheet_2_z_all$TS_freq)
grand_sheet_2_z_all$avg_comb_MM <- min_max_norm(grand_sheet_2_z_all$avg_comb)

#now, the binary CDR status column is either 0, or1, and the min-max transformed TF_Freq and avg_comb scores are also on the range of (0,1), we can assume they are on the same scale
grand_sheet_2_z_all$sort <- grand_sheet_2_z_all$TS_freq_MM +
        grand_sheet_2_z_all$avg_comb_MM +
        grand_sheet_2_z_all$CDR_status

 
#bind the sorting column back to grand_sheet_z_cont and grand_sheet_z_binary, and sort them according to the sort column
grand_sheet_2_z_cont <- cbind(grand_sheet_2_z_cont,grand_sheet_2_z_all$sort)
grand_sheet_2_z_cont <- rename(grand_sheet_2_z_cont,sort = "grand_sheet_2_z_all$sort")
grand_sheet_2_z_cont <- grand_sheet_2_z_cont[order(grand_sheet_2_z_cont$sort,decreasing = TRUE),]
#change the TS_Freq to ML_score
grand_sheet_2_z_cont <- grand_sheet_2_z_cont %>% rename(ML_score = TS_freq)

grand_sheet_2_z_binary <- cbind(grand_sheet_2_z_binary,grand_sheet_2_z_all$sort) %>%
        rename(sort = "grand_sheet_2_z_all$sort")

grand_sheet_2_z_binary <- grand_sheet_2_z_binary[order(grand_sheet_2_z_binary$sort,decreasing = TRUE),]



```



Plot heatmap
```{r convert to quartile break}
library(heatmap3)
library(pheatmap)
library(RColorBrewer)
library(viridis)

#use quantile breaks for the continuous heatmap, in this case each color will represents equal % of data
quantile_breaks <- function(xs, n = 10) {
  breaks <- quantile(xs, probs = seq(0, 1, length.out = n))
  breaks[!duplicated(breaks)]
}
#Verison 1
mat_breaks <- quantile_breaks(as.matrix(grand_sheet_z_cont), n = 7)

#Version 2
mat_breaks_2 <- quantile_breaks(as.matrix(grand_sheet_2_z_cont), n = 7)

```

Plot continuous df w/o any ranking, rather, by clustering the genes and predictors
```{r,fig.width=15,fig.height=30,fig.align="center"}
#version 1: crispr screens' z scores only calculated on the genes shown here(the genes used in experiment)
pheatmap(select(grand_sheet_z_cont,-"sort"),
         color = colorRampPalette(brewer.pal(n = 10, name =
  "YlOrRd"))(100),
         drop_levels = TRUE,
         border_color = NA,
         cellheight = 15,
         cellwidth = 20,
         fontsize_row = 15,
         fontsize_col = 15,
         cluster_cols = FALSE,
         cluster_rows = TRUE,
         angle_col = 45)
         #breaks = mat_breaks)

#version 2: crispr screens' z score calculated on all genes used in the initial screen
pheatmap(select(grand_sheet_2_z_cont,-"sort"),
         color = colorRampPalette(brewer.pal(n = 8, name =
  "YlOrRd"))(100),
         drop_levels = TRUE,
         border_color = NA,
         cellheight = 15,
         cellwidth = 20,
         fontsize_row = 15,
         fontsize_col = 15,
         cluster_cols = FALSE,
         cluster_rows = TRUE,
         angle_col = 45)

```



Plot the continuous df according to the sort column weighing the ML score, CDR status and experimental combined score equally
```{r,fig.width=15,fig.height=30,fig.align="center"}
#version 1: crispr screens' z scores only calculated on the genes shown here(the genes used in experiment)
pheatmap(select(grand_sheet_z_cont,-"sort"),
         color = colorRampPalette(brewer.pal(n = 10, name =
  "Oranges"))(100),
         #color = viridis(8),
         drop_levels = TRUE,
         border_color = NA,
         cellheight = 15,
         cellwidth = 20,
         fontsize_row = 15,
         fontsize_col = 15,
         cluster_cols = FALSE,
         cluster_rows = FALSE,
         angle_col = 45)
         #breaks = mat_breaks)

#version 2: crispr screens' z score calculated on all genes used in the initial screen
```

```{r,fig.width=12,fig.height=10}
pheatmap(select(grand_sheet_z_binary,-"sort"),
         color = viridis(8),
         drop_levels = TRUE,
         border_color = NA,
         fontsize_row = 6,
         fontsize_col = 8,
         cluster_cols = FALSE,
         cluster_rows = FALSE,
         angle_col = 45,
         cellwidth = 18,legend = FALSE)

         

```



